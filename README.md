# MongoDB + Kafka + Kafka Connect - Complete Example

ğŸš€ **Production-ready** MongoDB Kafka Connector example with real-time data synchronization using Docker.

![Architecture](https://img.shields.io/badge/Architecture-Microservices-blue)
![MongoDB](https://img.shields.io/badge/MongoDB-7.0-green)
![Kafka](https://img.shields.io/badge/Apache_Kafka-7.4.0-orange)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ğŸ“‹ Overview

This project demonstrates a complete, production-ready setup for real-time data synchronization between MongoDB and Apache Kafka using the MongoDB Source Connector. Perfect for:

- **Real-time analytics** and data streaming
- **Event-driven architectures** and microservices
- **Data pipeline** construction
- **Change Data Capture (CDC)** implementations

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MongoDB       â”‚    â”‚   Kafka         â”‚    â”‚   Consumers     â”‚
â”‚   Replica Set   â”‚â”€â”€â”€â–¶â”‚   + Connect     â”‚â”€â”€â”€â–¶â”‚   Applications  â”‚
â”‚   (3 nodes)     â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
     â”Œâ”€â”€â”€â–¼â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
     â”‚ Mongo â”‚              â”‚ Kafka   â”‚              â”‚ Your  â”‚
     â”‚Expressâ”‚              â”‚   UI    â”‚              â”‚ Apps  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Docker 20.0+ and Docker Compose
- 8GB+ RAM available
- Ports 27017-27019, 2181, 8080-8083, 9092 available

### One-Command Setup

```bash
# Clone the repository
git clone https://github.com/celfons/mongodb-kafka-connector-example.git
cd mongodb-kafka-connector-example

# Complete setup with sample data
make dev-setup

# Optional: Setup multiple filtered connectors for different operations
make setup-multi-connectors
```

**That's it!** ğŸ‰ Your environment is ready with filtered connectors for INSERT, UPDATE, DELETE operations.

### Manual Setup

```bash
# 1. Create environment file
make .env

# 2. Build and start services
make setup

# 3. Insert sample data (optional)
make sample-data
```

## ğŸŒ Access Points

After setup, access these services:

| Service | URL | Description |
|---------|-----|-------------|
| **Kafka UI** | http://localhost:8080 | Monitor Kafka topics and messages |
| **MongoDB Express** | http://localhost:8081 | MongoDB administration interface |
| **Kafka Connect API** | http://localhost:8083 | Connector management REST API |

**Default credentials:**
- MongoDB Express: `admin` / `admin`
- MongoDB: `admin` / `password123`

## ğŸ“Š Features

### Core Components

- âœ… **MongoDB Replica Set** (3 nodes) - High availability
- âœ… **Apache Kafka** with Zookeeper - Message streaming
- âœ… **Kafka Connect** with MongoDB Source Connector
- âœ… **Multiple Filtered Connectors** - Separate connectors for INSERT, UPDATE, DELETE operations
- âœ… **Kafka UI** - Visual monitoring and management
- âœ… **MongoDB Express** - Database administration
- âœ… **Health Checks** - Automated service monitoring
- âœ… **Sample Data** - Ready-to-use test datasets

### Production Features

- ğŸ”’ **Security**: Authentication and authorization
- ğŸ“Š **Monitoring**: Health checks and logging
- ğŸ”„ **High Availability**: Replica set configuration
- âš¡ **Performance**: Optimized configurations
- ğŸš¨ **Error Handling**: Dead letter queues
- ğŸ“– **Documentation**: Comprehensive guides

## âš™ï¸ Conectores MÃºltiplos com Filtros por OperaÃ§Ã£o

### ğŸ¯ VisÃ£o Geral

Este projeto agora inclui **conectores separados** para diferentes tipos de operaÃ§Ã£o do MongoDB, permitindo que cada tipo de evento seja enviado para tÃ³picos Kafka distintos:

- **ğŸŸ¢ INSERT Connector**: Captura apenas operaÃ§Ãµes de inserÃ§Ã£o â†’ TÃ³pico `mongo-insert.*`
- **ğŸŸ¡ UPDATE Connector**: Captura apenas operaÃ§Ãµes de atualizaÃ§Ã£o â†’ TÃ³pico `mongo-update.*`
- **ğŸ”´ DELETE Connector**: Captura apenas operaÃ§Ãµes de exclusÃ£o â†’ TÃ³pico `mongo-delete.*`

### ğŸ“ Estrutura dos Conectores

```
connectors/
â”œâ”€â”€ mongo-insert-connector.json   # Filtra apenas operaÃ§Ãµes INSERT
â”œâ”€â”€ mongo-update-connector.json   # Filtra apenas operaÃ§Ãµes UPDATE
â””â”€â”€ mongo-delete-connector.json   # Filtra apenas operaÃ§Ãµes DELETE
```

### ğŸ”§ ConfiguraÃ§Ã£o dos Filtros

Cada conector utiliza o **MongoDB Change Stream** com pipeline de agregaÃ§Ã£o para filtrar por `operationType`:

```json
{
  "name": "mongo-insert-connector",
  "config": {
    "connector.class": "com.mongodb.kafka.connect.MongoSourceConnector",
    "pipeline": "[{\"$match\": {\"operationType\": \"insert\"}}]",
    "topic.prefix": "mongo-insert",
    "database": "exemplo",
    ...
  }
}
```

**Tipos de operaÃ§Ã£o disponÃ­veis:**
- `insert` - InserÃ§Ã£o de novos documentos
- `update` - AtualizaÃ§Ã£o de documentos existentes
- `delete` - ExclusÃ£o de documentos
- `replace` - SubstituiÃ§Ã£o completa de documentos

### ğŸš€ Como Usar os Conectores MÃºltiplos

#### OpÃ§Ã£o 1: Setup Completo (Recomendado para novos projetos)
```bash
# 1. ConfiguraÃ§Ã£o inicial completa
make dev-setup

# 2. Configurar conectores mÃºltiplos com filtros
make setup-multi-connectors
```

#### OpÃ§Ã£o 2: Apenas Conectores MÃºltiplos (Para projetos existentes)
```bash
# Configurar apenas os conectores com filtros (requer ambiente jÃ¡ iniciado)
make setup-multi-connectors
```

#### OpÃ§Ã£o 3: Manual
```bash
# Executar script diretamente
./scripts/setup-multi-connectors.sh
```

### ğŸ“‹ TÃ³picos Kafka Criados

ApÃ³s a configuraÃ§Ã£o, os seguintes tÃ³picos serÃ£o criados automaticamente:

| Conector | TÃ³pico de Exemplo | DescriÃ§Ã£o |
|----------|------------------|-----------|
| **INSERT** | `mongo-insert.exemplo.users` | Apenas inserÃ§Ãµes de usuÃ¡rios |
| **UPDATE** | `mongo-update.exemplo.users` | Apenas atualizaÃ§Ãµes de usuÃ¡rios |
| **DELETE** | `mongo-delete.exemplo.users` | Apenas exclusÃµes de usuÃ¡rios |
| **INSERT** | `mongo-insert.exemplo.products` | Apenas inserÃ§Ãµes de produtos |
| **UPDATE** | `mongo-update.exemplo.products` | Apenas atualizaÃ§Ãµes de produtos |
| **DELETE** | `mongo-delete.exemplo.products` | Apenas exclusÃµes de produtos |

### ğŸ“„ Exemplo de Mensagem Kafka

**Mensagem de INSERT** (tÃ³pico: `mongo-insert.exemplo.users`):
```json
{
  "_id": {
    "_data": "82644F2A8D000000012B0429296E1404"
  },
  "operationType": "insert",
  "clusterTime": {
    "$timestamp": {
      "t": 1682951293,
      "i": 1
    }
  },
  "ns": {
    "db": "exemplo",
    "coll": "users"
  },
  "documentKey": {
    "_id": {
      "$oid": "644f2a8d1234567890abcdef"
    }
  },
  "fullDocument": {
    "_id": {
      "$oid": "644f2a8d1234567890abcdef"
    },
    "name": "JoÃ£o Silva",
    "email": "joao@exemplo.com",
    "createdAt": {
      "$date": "2023-05-01T12:34:56.789Z"
    }
  }
}
```

**Mensagem de UPDATE** (tÃ³pico: `mongo-update.exemplo.users`):
```json
{
  "_id": {
    "_data": "82644F2A8E000000012B0429296E1404"
  },
  "operationType": "update",
  "clusterTime": {
    "$timestamp": {
      "t": 1682951294,
      "i": 1
    }
  },
  "ns": {
    "db": "exemplo",
    "coll": "users"
  },
  "documentKey": {
    "_id": {
      "$oid": "644f2a8d1234567890abcdef"
    }
  },
  "updateDescription": {
    "updatedFields": {
      "status": "active",
      "lastLogin": {
        "$date": "2023-05-01T12:35:56.789Z"
      }
    },
    "removedFields": []
  },
  "fullDocument": {
    "_id": {
      "$oid": "644f2a8d1234567890abcdef"
    },
    "name": "JoÃ£o Silva",
    "email": "joao@exemplo.com",
    "status": "active",
    "lastLogin": {
      "$date": "2023-05-01T12:35:56.789Z"
    },
    "createdAt": {
      "$date": "2023-05-01T12:34:56.789Z"
    }
  }
}
```

**Mensagem de DELETE** (tÃ³pico: `mongo-delete.exemplo.users`):
```json
{
  "_id": {
    "_data": "82644F2A8F000000012B0429296E1404"
  },
  "operationType": "delete",
  "clusterTime": {
    "$timestamp": {
      "t": 1682951295,
      "i": 1
    }
  },
  "ns": {
    "db": "exemplo",
    "coll": "users"
  },
  "documentKey": {
    "_id": {
      "$oid": "644f2a8d1234567890abcdef"
    }
  }
}
```

### ğŸ§ª Testando os Filtros

1. **Inicie o ambiente**:
   ```bash
   make dev-setup
   make setup-multi-connectors
   ```

2. **Insira dados de teste**:
   ```bash
   make sample-data
   ```

3. **Monitore os tÃ³picos** em tempo real:
   ```bash
   # OpÃ§Ã£o 1: Via interface web (Recomendado)
   # Acesse http://localhost:8080 e visualize os tÃ³picos
   
   # OpÃ§Ã£o 2: Via linha de comando
   make monitor-topics
   ```

4. **Teste operaÃ§Ãµes especÃ­ficas**:
   ```bash
   # Conectar ao MongoDB e fazer operaÃ§Ãµes manuais
   docker-compose exec mongo1 mongosh "mongodb://admin:password123@localhost:27017/exemplo?authSource=admin"
   
   # Inserir documento (aparecerÃ¡ em mongo-insert.exemplo.*)
   db.users.insertOne({name: "Teste Insert", email: "insert@test.com"})
   
   # Atualizar documento (aparecerÃ¡ em mongo-update.exemplo.*)
   db.users.updateOne({name: "Teste Insert"}, {$set: {status: "updated"}})
   
   # Excluir documento (aparecerÃ¡ em mongo-delete.exemplo.*)
   db.users.deleteOne({name: "Teste Insert"})
   ```

### ğŸ” Monitoramento e VerificaÃ§Ã£o

#### Via Kafka UI (Interface Web)
- **URL**: http://localhost:8080
- Visualize mensagens em tempo real
- Analise configuraÃ§Ã£o dos conectores
- Monitore performance e mÃ©tricas

#### Via API do Kafka Connect
```bash
# Status de todos os conectores
curl -s http://localhost:8083/connectors | jq

# Status especÃ­fico do conector INSERT
curl -s http://localhost:8083/connectors/mongo-insert-connector/status | jq

# Status especÃ­fico do conector UPDATE
curl -s http://localhost:8083/connectors/mongo-update-connector/status | jq

# Status especÃ­fico do conector DELETE
curl -s http://localhost:8083/connectors/mongo-delete-connector/status | jq
```

### âš ï¸ ObservaÃ§Ãµes Importantes

1. **Change Streams**: Requer MongoDB em modo Replica Set (jÃ¡ configurado neste projeto)
2. **Performance**: Conectores mÃºltiplos consomem mais recursos - monitore o uso
3. **Dead Letter Queues**: Cada conector tem sua prÃ³pria DLQ para tratamento de erros
4. **TÃ³picos**: Os tÃ³picos sÃ£o criados automaticamente quando as primeiras mensagens chegam

### ğŸ›ï¸ PersonalizaÃ§Ã£o dos Conectores

Para personalizar os conectores, edite os arquivos JSON em `connectors/`:

```bash
# Editar configuraÃ§Ã£o do conector INSERT
nano connectors/mongo-insert-connector.json

# Aplicar mudanÃ§as (requer reinicializaÃ§Ã£o do conector)
make setup-multi-connectors
```

**ConfiguraÃ§Ãµes que podem ser personalizadas:**
- Database e collections especÃ­ficas
- Filtros mais complexos no pipeline
- ConfiguraÃ§Ãµes de performance (batch size, poll intervals)
- TÃ³picos de destino
- FormataÃ§Ã£o das mensagens

## ğŸ› ï¸ Available Commands

```bash
# Essential commands
make help                    # Show all available commands
make status                  # Check service health
make logs                    # View all service logs

# Development
make dev-setup              # Complete development setup
make sample-data            # Insert test data
make monitor-topics         # Watch Kafka messages

# Connector Management
make setup-multi-connectors # Setup multiple filtered connectors (INSERT, UPDATE, DELETE)

# Management
make clean                  # Clean up everything
make backup                 # Backup MongoDB data
make restart-*              # Restart specific services
```

## ğŸ“ Configuration

### Environment Variables

Key configurations in `.env`:

```bash
# MongoDB
MONGO_INITDB_ROOT_USERNAME=admin
MONGO_INITDB_ROOT_PASSWORD=password123
MONGO_REPLICA_SET_NAME=rs0

# Kafka
KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092

# Ports
KAFKA_UI_PORT=8080
MONGO_EXPRESS_PORT=8081
```

### Connector Configuration

The MongoDB Source Connector is configured in `config/kafka-connect/mongodb-source-connector.json`:

- **Change Streams**: Real-time change capture
- **Multiple Collections**: All collections in database
- **Error Handling**: Dead letter queue for failed messages
- **JSON Format**: Simplified JSON output

## ğŸ§ª Testing Real-time Sync

1. **Insert data** into MongoDB:
   ```bash
   make sample-data
   ```

2. **Monitor Kafka topics**:
   ```bash
   make monitor-topics
   ```

3. **View in Kafka UI**:
   - Open http://localhost:8080
   - Check topics: `mongodb.exemplo.users`, `mongodb.exemplo.products`

4. **Make changes** in MongoDB Express:
   - Open http://localhost:8081
   - Update documents and see changes in Kafka

## ğŸ“š Documentation

- ğŸ“– [Detailed Setup Guide](docs/SETUP.md)
- â˜ï¸ [MongoDB Atlas Integration](docs/ATLAS_SETUP.md)
- ğŸ”§ [Troubleshooting Guide](docs/TROUBLESHOOTING.md)

## ğŸ­ Production Deployment

### Azure Cloud Deployment (Automatizado) ğŸš€

Este projeto inclui uma esteira de CI/CD completa para deploy automatizado no Azure:

- âœ… **Build e Push automatizado** para Azure Container Registry (ACR)
- âœ… **Deploy para Azure Web App for Containers** ou Azure Container Instances
- âœ… **ConfiguraÃ§Ã£o automÃ¡tica** de variÃ¡veis de ambiente
- âœ… **IntegraÃ§Ã£o com MongoDB Atlas** para produÃ§Ã£o
- âœ… **VerificaÃ§Ã£o de saÃºde** automÃ¡tica da aplicaÃ§Ã£o

#### ğŸ”§ ConfiguraÃ§Ã£o RÃ¡pida

1. **Configure os Secrets no GitHub** (obrigatÃ³rio):
   ```bash
   # Azure Container Registry
   ACR_REGISTRY=<seu-registry>.azurecr.io
   ACR_USERNAME=<username-do-acr>
   ACR_PASSWORD=<password-do-acr>
   
   # Azure Web App
   AZURE_WEBAPP_NAME=<nome-do-web-app>
   AZURE_RESOURCE_GROUP=<nome-do-resource-group>
   
   # Credenciais Azure (JSON do service principal)
   AZURE_CREDENTIALS=<json-das-credenciais>
   
   # MongoDB Atlas produtivo
   MONGODB_ATLAS_CONNECTION_STRING=mongodb+srv://<user>:<pass>@<cluster>.mongodb.net/<db>
   ```

2. **Deploy AutomÃ¡tico**:
   - Push na branch `main` â†’ Deploy automÃ¡tico para produÃ§Ã£o
   - Dispatch manual â†’ Deploy para staging/development

3. **Acesso Ã  AplicaÃ§Ã£o**:
   - **URL**: `https://<webapp-name>.azurewebsites.net:8083`
   - **API Connectors**: `/connectors`
   - **Health Check**: `/connector-plugins`

#### ğŸ“š DocumentaÃ§Ã£o Completa

Veja a [documentaÃ§Ã£o completa do CI/CD](.github/workflows/README.md) para:
- ConfiguraÃ§Ã£o detalhada dos secrets
- Como obter credenciais Azure
- Troubleshooting e soluÃ§Ã£o de problemas
- CustomizaÃ§Ã£o da pipeline

#### ğŸ” Exemplos de ConfiguraÃ§Ã£o dos Secrets

**Como configurar os secrets no GitHub:**

1. Acesse `Settings` â†’ `Secrets and variables` â†’ `Actions` no seu repositÃ³rio
2. Clique em `New repository secret` para cada um:

```bash
# Exemplo de AZURE_CREDENTIALS (JSON do service principal):
{
  "clientId": "12345678-1234-1234-1234-123456789012",
  "clientSecret": "sua-secret-key-aqui",
  "subscriptionId": "87654321-4321-4321-4321-210987654321",
  "tenantId": "11111111-2222-3333-4444-555555555555"
}

# Exemplo de ACR_REGISTRY:
meuregistry.azurecr.io

# Exemplo de MONGODB_ATLAS_CONNECTION_STRING:
mongodb+srv://admin:password123@cluster0.abcde.mongodb.net/producao?retryWrites=true&w=majority
```

**Como obter as credenciais Azure:**
```bash
# 1. Login no Azure CLI
az login

# 2. Criar service principal
az ad sp create-for-rbac \
  --name "mongodb-kafka-cd" \
  --role contributor \
  --scopes /subscriptions/YOUR_SUBSCRIPTION_ID \
  --sdk-auth

# 3. Habilitar admin no ACR
az acr update --name SEU_REGISTRY --admin-enabled true

# 4. Obter credenciais do ACR
az acr credential show --name SEU_REGISTRY
```

### Deployment Tradicional

Para ambientes on-premise ou outras clouds:

1. **Security**: Configure authentication e TLS
2. **Scaling**: Aumente replica set e partiÃ§Ãµes do Kafka
3. **Monitoring**: Configure logs e alertas
4. **Networking**: Configure seguranÃ§a de rede adequada
5. **Backup**: Implemente estratÃ©gias de backup automatizado

Veja o [Guia de Setup para ProduÃ§Ã£o](docs/SETUP.md#production-deployment) para detalhes.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make changes with tests
4. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- ğŸ“– Check the [Troubleshooting Guide](docs/TROUBLESHOOTING.md)
- ğŸ› Report issues on GitHub
- ğŸ’¬ Join our community discussions

---

**Made with â¤ï¸ for the MongoDB and Kafka community**